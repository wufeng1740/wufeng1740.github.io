<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>① MNIST Machine Learning</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="122620a8-da3a-8055-8bf3-eea5e2b535f1" class="page sans"><header><h1 class="page-title">① MNIST Machine Learning</h1><p class="page-description"></p></header><div class="page-body"><div><p id="122620a8-da3a-8081-8bf9-fe01790c7130" class=""><a href="https://wufeng1740.github.io/">← back to Resume</a></p></div><h1 id="122620a8-da3a-8050-868b-f4c3f87e2a5b" class="">Introduction</h1><div><blockquote id="122620a8-da3a-800c-9bc4-c5cf0896e32e" class=""><strong><a href="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1.html">MNIST Machine Learning</a></strong> project involves using the MNIST dataset to build a machine learning model for recognizing handwritten digits, helping to classify images of numbers from 0 to 9 with high accuracy, including using PCA, K-means and Kernel Methods.</blockquote></div><h1 id="122620a8-da3a-806b-9645-dab6c6cab194" class="">Code &amp; Images</h1><h2 id="122620a8-da3a-8086-9bbe-e5fff6de3d96" class="">K-means clustering</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-805b-acf5-fd441d0a6051" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import random
seed = 0
random.seed(seed)

loss = []

def k_means(x, k = 2 , epochs = 600, print_initial_center = False):
    &#x27;&#x27;&#x27; 
    Parameters:
        x: input data
        k: number of clusters
        epochs: number of iterations
    &#x27;&#x27;&#x27;
    # 1. Randomly initialize k centroids
    np.random.seed(2024)
    clusters = []
    # &quot;you need to randomly initialize k centroids using x&quot;
    random_list = np.random.choice(x.shape[0], k, replace=False)
    cluster_center = x[np.random.choice(x.shape[0], k, replace=False)]
    if print_initial_center:
        print(&#x27;the initial cluster center is&#x27;, len(set(y[random_list])), &#x27; - &#x27;, y[random_list])
        # replace=False -&gt; no duplicate centroids
    for i in range(k):
        clusters.append([])

    # 2. Training
    for _ in range(epochs):
        new_clusters_center = np.zeros((k, x.shape[1]))
        for i in range(k):
            clusters[i]=[]
        ## a. E-step: finding points to the nearest centroid, assigning to corresponding clusters
        ## Calculate the distance from all points to the k cluster centers
        for i in range(x.shape[0]):
            xi = x[i]
            # &quot;Calculate the distance of xi with each centroid using norm2&quot;
            distances = [np.linalg.norm(xi - cluster_center[j]) for j in range(k)]
            # Returns the index of the nearest centriod to this datapoint
            c = distances.index(min(distances))
                # c: index of the nearest centroid
            clusters[c].append(i) # Append this datapoint to this cluster

        ## b. M-step: recalculate the location of the centroid using the mean of the clusters
        for i in range(k):
            # &quot;You need to calculate the position of the new centroids&quot;
            new_clusters_center[i] = np.mean(x[clusters[i]], axis=0)

        # c. If the centroid did not change, the algorithm should be stopped, otherwise continue.
        if np.all(new_clusters_center == cluster_center):
            return clusters, new_clusters_center

        # d. update the centroid
        loss.append(abs(np.sum(new_clusters_center - cluster_center)))
        cluster_center = new_clusters_center

    return clusters, cluster_center

k = 10
clusters, cluster_center = k_means(x, k)</code></pre><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-809c-bd04-d167f68188f1" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import matplotlib.pyplot as plt
import numpy as np
# Create figure
figure = plt.figure(figsize=(16, 2))

# for 10 centers
for i in range(10):
    ax = figure.add_subplot(1, 10, i + 1)  # 1 row 9 column layout
    pixels = cluster_center[i].reshape((28, 28))
    
    # show images
    temp = ax.imshow(pixels, cmap=&#x27;gray&#x27;)
    
    # turn off axis
    temp = ax.axis(&#x27;off&#x27;)

# plot
plt.show()</code></pre><figure id="122620a8-da3a-80e3-bba9-dd2b2091886a" class="image"><a href="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image.png"><img style="width:1046.9296875px" src="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image.png"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-80dd-b10c-f1d3974e1fde" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def k_mean_cluster_number(clusters, y):
    cluster_number = []
    for i in range(k):
        current_cluster = clusters[i]
        current_y = y[current_cluster]
        # find the most common number in the cluster
        most_common = np.argmax(np.bincount(current_y))
        cluster_number.append(most_common)
    return cluster_number

k = 10
print(k_mean_cluster_number(clusters, y))</code></pre><blockquote id="122620a8-da3a-803c-a3c8-e4a53fb05715" class="">output: [0, 8, 2, 3, 1, 3, 7, 4, 8, 6]</blockquote><h2 id="122620a8-da3a-8035-bd3f-c23d2163a728" class="">Find best K in K-means</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-80db-ab07-ebe2a79e1448" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># use 10-divided data to test the best K
import time
x_train, x_test = x[:4000], x[4000:]
y_train, y_test = y[:4000], y[4000:]

# Method
    # divide K to 10 pieces, get 10 accuracy, save into dictionary
    # get the best 2, divide again
    # if no new K, stop

def k_mean_cluster_number(clusters, y):
    # get the most common number in each cluster, as the cluster representative
    cluster_number = []
    for i in range(len(clusters)):
        current_cluster = clusters[i]
        current_y = y[current_cluster]
        # find the most common number in the cluster
        most_common = np.argmax(np.bincount(current_y))
        cluster_number.append(most_common)
    return cluster_number

def predict(clusters, cluster_center, y_train, xi):
    # get the predicted result from the closest cluster
    cluster_number = k_mean_cluster_number(clusters, y_train)
    distances = [np.linalg.norm(xi - cluster_center[j]) for j in range(len(cluster_center))]
    min_dis_index = distances.index(min(distances))
    y_pred = cluster_number[min_dis_index]
    return y_pred

def accuracy(clusters, cluster_center, y_train, x_test, y_test):
    correct = 0
    for i in range(len(x_test)):
        y_pred = predict(clusters, cluster_center, y_train, x_test[i])
        if y_pred == y_test[i]:
            correct += 1
    return correct / len(x_test)

def get_n_number_from_range(start, end, n):
    if end&lt;=start:
        start, end = end, start
    l = np.linspace(start, end, n, dtype=int)
    l = np.unique(l)
    l = list(l)
    return l

def get_accuracy_into_dict(x_train, y_train, x_test, y_test, k_list):
    k_in_dict = []
    for k in k_list:
        if k not in accuracy_dict.keys():
            start_time = time.time()
            clusters, cluster_center = k_means(x_train, k)
            accuracy_rate = accuracy(clusters, cluster_center, y_train, x_test, y_test)
            time_cost = time.time() - start_time
            print(f&#x27;t={time_cost:6.2f}s, k={k:4} - Accuracy rate: {accuracy_rate}&#x27;)
            accuracy_dict[k] = accuracy_rate
        else:
            k_in_dict.append(False)
    return len(k_list)-len(k_in_dict)
    
def get_max_2_from_dict(accuracy_dict):
    max_2 = sorted(accuracy_dict.items(), key=lambda x: x[1], reverse=True)[:2]
    result = [i[0] for i in max_2]
    result.sort()
    return result

# parameters
start = 2
end = len(x_train)-1
divide = 10
tolerance = 10
accuracy_dict = {}

# run the method
while tolerance &gt; 0:
    k_list = get_n_number_from_range(start, end, divide+1)
    print(f&#x27;----------{k_list}----------&#x27;)
    new_k_number = get_accuracy_into_dict(x_train, y_train, x_test, y_test, k_list)
    if new_k_number == 0:
        break
    start, end = get_max_2_from_dict(accuracy_dict)
    tolerance -= 1

# get best k
best_k = get_max_2_from_dict(accuracy_dict)[0]
best_accuracy = accuracy_dict[best_k]
print(f&#x27;The optimal k is {best_k} with an accuracy rate of {best_accuracy}&#x27;)</code></pre><blockquote id="122620a8-da3a-8042-9515-f592b87126f0" class="">---------[2, 401, 801, 1201, 1600, 2000, 2400, 2799, 3199, 3599, 3999]----------<br/>t= 0.98s, k= 2 - Accuracy rate: 0.2155<br/>t= 46.17s, k= 401 - Accuracy rate: 0.879<br/>t= 66.29s, k= 801 - Accuracy rate: 0.899<br/>t= 77.24s, k=1201 - Accuracy rate: 0.9055<br/>t= 76.35s, k=1600 - Accuracy rate: 0.906<br/>t= 78.92s, k=2000 - Accuracy rate: 0.9105<br/>t= 94.07s, k=2400 - Accuracy rate: 0.9175<br/>t=110.12s, k=2799 - Accuracy rate: 0.925<br/>t=126.86s, k=3199 - Accuracy rate: 0.928<br/>t=116.47s, k=3599 - Accuracy rate: 0.9305<br/>t= 90.95s, k=3999 - Accuracy rate: 0.933<br/>----------[3599, 3639, 3679, 3719, 3759, 3799, 3839, 3879, 3919, 3959, 3999]----------<br/>t=112.00s, k=3639 - Accuracy rate: 0.9305<br/>t=115.66s, k=3679 - Accuracy rate: 0.93<br/>t=115.42s, k=3719 - Accuracy rate: 0.9305<br/>t=116.64s, k=3759 - Accuracy rate: 0.9305<br/>t=118.10s, k=3799 - Accuracy rate: 0.932<br/>t=125.24s, k=3839 - Accuracy rate: 0.9335<br/>t=123.49s, k=3879 - Accuracy rate: 0.935<br/>t=120.79s, k=3919 - Accuracy rate: 0.935<br/>t=120.68s, k=3959 - Accuracy rate: 0.9335<br/>----------[3879, 3883, 3887, 3891, 3895, 3899, 3903, 3907, 3911, 3915, 3919]----------<br/>t=117.72s, k=3883 - Accuracy rate: 0.935<br/>t=118.46s, k=3887 - Accuracy rate: 0.935<br/>t=120.62s, k=3891 - Accuracy rate: 0.935<br/>t=120.66s, k=3895 - Accuracy rate: 0.9345<br/>t=120.08s, k=3899 - Accuracy rate: 0.9355<br/>t=123.20s, k=3903 - Accuracy rate: 0.9355<br/>t=122.83s, k=3907 - Accuracy rate: 0.9365<br/>t=122.17s, k=3911 - Accuracy rate: 0.9365<br/>t=119.37s, k=3915 - Accuracy rate: 0.936<br/>----------[3907, 3908, 3909, 3910, 3911]----------<br/>t=118.79s, k=3908 - Accuracy rate: 0.9365<br/>t=118.53s, k=3909 - Accuracy rate: 0.9365<br/>t=119.35s, k=3910 - Accuracy rate: 0.9365<br/>----------[3907, 3908, 3909, 3910, 3911]----------<br/>The optimal k is 3907 with an accuracy rate of 0.9365<br/></blockquote><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-803c-95ab-ffc1a1d752ea" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def plot_dict(d: dict):
    x_value = [i for i in d.keys()]
    y_value = [i for i in d.values()]
    figure = plt.figure(figsize=(12, 4))
    temp = plt.plot(x_value, y_value, marker=&#x27;.&#x27;)
    temp = plt.title(&#x27;Accuracy rate vs. k&#x27;)
    plt.show()
plot_dict(accuracy_dict)</code></pre><figure id="122620a8-da3a-801b-a69f-e03244a90b8d" class="image"><a href="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image%201.png"><img style="width:1046.984375px" src="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image%201.png"/></a></figure><h2 id="122620a8-da3a-8031-b39f-f375b27cd3a5" class="">K-means with RBF-kernel</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-8083-8d67-f94fb23440b8" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">x_train2, x_test2 = x[:500], x[500:1000]
y_train2, y_test2 = y[:500], y[500:1000]


def cal_RBF(x):
    ## implement RBF method
    n = x.shape[0]
    # &quot;You need to initialize k&quot;
    kernel_x = np.zeros((n, n))
    sigma = 0

    for i in range(n):
        for j in range(n):
            # &quot;You need to implement sigma here&quot;
            sigma += (np.linalg.norm(x[i] - x[j], ord=2))**2
    sigma = sigma/(n**2)

    for i in range(n):
        for j in range(n):
            # &quot;You need to implement kernel x here&quot;
            kernel_x[i, j] = np.exp(-(np.linalg.norm(x[i] - x[j], ord=2))**2 / (2 * sigma**2))
    # kernel_x = k
    return kernel_x
kernel_x = cal_RBF(x_train2)
clusters, cluster_center = k_means(kernel_x, 5)</code></pre><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="122620a8-da3a-80dc-9a65-ddf571fbcd9c" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def plot_clusters(clusters, y_train):
    x_value = []
    y_value = []
    c_value = []
    for i in range(len(clusters)):
        for j in clusters[i]:
            x_value.append(j)
            y_value.append(i)
            c_value.append(y_train[j])
    figure_height = max(15*len(set(y_value))//len(x_value), 3)
    figure = plt.figure(figsize=(15, figure_height))
    temp = plt.scatter(x_value, y_value, marker=&#x27;o&#x27;, c=c_value)
    plt.show()
plot_clusters(clusters, y_train2)</code></pre><figure id="122620a8-da3a-8068-831a-c3d6758c94a1" class="image"><a href="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image%202.png"><img style="width:1046.96875px" src="%E2%91%A0%20MNIST%20Machine%20Learning%20122620a8da3a80558bf3eea5e2b535f1/image%202.png"/></a></figure></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>